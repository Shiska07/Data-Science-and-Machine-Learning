{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Computational Graph (Implementation and Examples)\n",
    "The following code is a simple implementation of the forward pass for a computational graph.\n",
    "\n",
    "Farhad Kamangar  Oct. 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Node:\n",
    "    def __init__(self, input_nodes=[]):\n",
    "        self.input_nodes = input_nodes\n",
    "        self.consumers = []\n",
    "        for input_node in input_nodes:\n",
    "            input_node.consumers.append(self)\n",
    "        global_default_graph.operations.append(self)\n",
    "    def compute(self):\n",
    "        pass\n",
    "class add(Node):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__([x, y])\n",
    "    def compute(self, x_value, y_value):\n",
    "        return x_value + y_value\n",
    "class matmul(Node):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__([x, y])\n",
    "    def compute(self, x_value, y_value):\n",
    "        return x_value.dot(y_value)\n",
    "class sigmoid(Node):\n",
    "    def __init__(self, x):\n",
    "        super().__init__([x])\n",
    "    def compute(self, x_value):\n",
    "        return 1/(1+np.exp(-x_value))\n",
    "class placeholder:\n",
    "    def __init__(self):\n",
    "        self.consumers = []\n",
    "        global_default_graph.placeholders.append(self)\n",
    "class Variable:\n",
    "    def __init__(self, initial_value=None):\n",
    "        self.value = initial_value\n",
    "        self.consumers = []\n",
    "        global_default_graph.variables.append(self)\n",
    "class Graph:\n",
    "    def __init__(self):\n",
    "        self.operations = []\n",
    "        self.placeholders = []\n",
    "        self.variables = [1,2,3]\n",
    "    def create_default_graph(self):\n",
    "        global global_default_graph\n",
    "        global_default_graph = self\n",
    "class Session:\n",
    "    def run(self, target_node, feed_dict={}):\n",
    "        postorder_nodes_list = postorder(target_node)\n",
    "        for node in postorder_nodes_list:\n",
    "            if type(node) == placeholder:\n",
    "                node.output = feed_dict[node]\n",
    "            elif type(node) == Variable:\n",
    "                node.output = node.value\n",
    "            else:\n",
    "                node.inputs=[]\n",
    "                for input_node in node.input_nodes:\n",
    "                    node.inputs.append(input_node.output)\n",
    "                node.output = node.compute(*node.inputs)\n",
    "            if type(node.output) == list:\n",
    "                node.output = np.array(node.output)\n",
    "        return target_node.output\n",
    "def postorder(operation):\n",
    "    postorder_nodes_list = []\n",
    "    def recursive_traverse(node):\n",
    "        if isinstance(node, Node):\n",
    "            for input_node in node.input_nodes:\n",
    "                recursive_traverse(input_node)\n",
    "        postorder_nodes_list.append(node)\n",
    "    recursive_traverse(operation)\n",
    "    return postorder_nodes_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example #1\n",
    "The following code creates a computational graph for the equation $y=ax+b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y= [23]\n"
     ]
    }
   ],
   "source": [
    "# Example #1: y=a*b+c \n",
    "\n",
    "Graph().create_default_graph()  # Create a new graph\n",
    "a=Variable([3])\n",
    "x = Variable([5])\n",
    "c = Variable([8])\n",
    "ax=matmul(a,x)  # ax is the temp name of the matmul node\n",
    "y=add(ax,c)\n",
    "session = Session()\n",
    "output = session.run(y)\n",
    "print(\"y=\",output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example #2\n",
    "The following code creates a computational graph for the equation $Y=AX+B$\n",
    "\n",
    "The difference between this example and the previous one is that this example works with numpy arrays\n",
    "Note:\n",
    "A and B are variables\n",
    "AX is an intermediate node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A= [[1 2]\n",
      " [5 3]]\n",
      "B= [[5]\n",
      " [4]]\n",
      "X= [[1 5 7 5 2]\n",
      " [2 6 9 3 8]]\n",
      "Y= [[10 22 30 16 23]\n",
      " [15 47 66 38 38]]\n"
     ]
    }
   ],
   "source": [
    "A=Variable(np.array([[1, 2], [5, 3]]))\n",
    "X=Variable(np.array([[1,5,7,5,2],[2,6,9,3,8]]))\n",
    "B = Variable(np.array([[5],[4]]))\n",
    "AX = matmul(A, X)\n",
    "Y = add(AX,B)\n",
    "session = Session()\n",
    "output = session.run(Y)\n",
    "print(\"A=\",A.value)\n",
    "print(\"B=\",B.value)\n",
    "print(\"X=\",X.output)\n",
    "print(\"Y=\",Y.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example #3\n",
    "The following code creates a computational graph for the equation $Y=AX+B$\n",
    "\n",
    "The difference between this example and the previous one is that X is defined as a place holder.\n",
    "A placeholder is a variable that we will assign data to it when we run the session. It allows us to create the computation graph without needing the data.\n",
    "Note:\n",
    "A and B are variables\n",
    "AX is an intermediate node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A= [[1 2]\n",
      " [5 3]]\n",
      "B= [[5]\n",
      " [4]]\n",
      "X= [[1 5 7 5 2]\n",
      " [2 6 9 3 8]]\n",
      "Y= [[10 22 30 16 23]\n",
      " [15 47 66 38 38]]\n"
     ]
    }
   ],
   "source": [
    "A=Variable(np.array([[1, 2], [5, 3]]))\n",
    "X = placeholder()\n",
    "B = Variable(np.array([[5],[4]]))\n",
    "AX = matmul(A, X)\n",
    "Y = add(AX,B)\n",
    "session = Session()\n",
    "output = session.run(Y, {X: np.array([[1,5,7,5,2],[2,6,9,3,8]])})\n",
    "print(\"A=\",A.value)\n",
    "print(\"B=\",B.value)\n",
    "print(\"X=\",X.output)\n",
    "print(\"Y=\",Y.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example #4\n",
    "The following code creates a computational graph for a single neuron with sigmoid activation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights= [[ 0.02254587 -0.83461608]]\n",
      "bias= [[0.46545614]]\n",
      "X= [[1 5 7 5 2]\n",
      " [2 6 9 3 8]]\n",
      "output= [[0.23483108 0.0117799  0.00101864 0.12723143 0.00209442]]\n"
     ]
    }
   ],
   "source": [
    "# Example #4: single neuron with sigmoid activation\n",
    "weights=Variable(np.random.randn(1,2))\n",
    "bias=Variable(np.random.randn(1,1))\n",
    "X = placeholder()\n",
    "WX = matmul(weights,X)\n",
    "net=add(WX,bias)\n",
    "a=sigmoid(net)\n",
    "\n",
    "session = Session()\n",
    "output = session.run(a, {X: np.array([[1,5,7,5,2],[2,6,9,3,8]])})\n",
    "print(\"weights=\",weights.value)\n",
    "print(\"bias=\",bias.value)\n",
    "print(\"X=\",X.output)\n",
    "print(\"output=\",output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example #4\n",
    "The following code creates a computational graph for a single layer of neurons with sigmoid activation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights= [[ 1.05388052e+00  1.56509813e+00  4.91534235e-01  1.06411649e+00\n",
      "   4.85007033e-01 -1.23921998e+00  5.50302413e-01 -4.52099888e-01\n",
      "   1.29024265e+00  1.53990063e+00]\n",
      " [-2.94724443e+00  6.83339418e-01 -5.04842489e-01 -1.50325680e+00\n",
      "  -1.47939769e-01 -3.40681532e-01 -6.02712826e-01  1.09762365e+00\n",
      "  -4.43516416e-01 -8.68603601e-02]\n",
      " [-9.68173272e-01 -7.75999293e-01  1.87545466e+00  7.25124028e-02\n",
      "  -2.75314387e-01  2.52486735e+00 -7.45182470e-01 -1.21869801e+00\n",
      "  -5.10034816e-01  2.37350183e+00]\n",
      " [ 8.37077432e-01 -5.68456521e-02 -1.85735192e+00 -7.23362678e-01\n",
      "  -2.12724479e-01 -2.58164057e+00  8.45586048e-01  1.53971428e-03\n",
      "   4.18172397e-01  1.61802068e+00]\n",
      " [ 5.46629350e-01 -8.14861057e-01 -5.69135807e-01  1.64763550e+00\n",
      "  -5.48009929e-01 -8.28541942e-01 -5.83146345e-01 -7.96672155e-01\n",
      "   1.02237622e-02  3.53976780e-02]]\n",
      "bias= [[-0.78657798]\n",
      " [ 0.06280816]\n",
      " [-0.71284611]\n",
      " [ 1.5157049 ]\n",
      " [ 0.98210131]]\n",
      "X= [[-0.77638989  0.45450213  0.90849114]\n",
      " [-0.24181127 -0.27384975 -1.79735325]\n",
      " [ 1.79642801 -0.4202338   0.53999547]\n",
      " [-1.05576592 -0.2091367   1.24465348]\n",
      " [-1.60207933  0.89941496  0.86005374]\n",
      " [-0.90935108  0.32439612 -1.46290926]\n",
      " [-0.60797163 -0.23289101  0.3864414 ]\n",
      " [-0.4546662   0.45381898 -2.09559635]\n",
      " [ 0.76592454 -0.62814228 -0.48123011]\n",
      " [-0.86716644  0.5610865  -0.01005803]]\n",
      "output= [[8.70673908e-02 1.96101608e-01 8.45717039e-01]\n",
      " [9.53281341e-01 4.22493429e-01 3.58143614e-04]\n",
      " [5.55373998e-01 5.25068315e-01 3.68740438e-01]\n",
      " [3.53766695e-01 9.05823577e-01 9.84855232e-01]\n",
      " [5.78861056e-01 5.92503328e-01 9.98958807e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Example #5: One layer with multiple neurons with sigmoid activation\n",
    "input_dimensions=10\n",
    "number_of_neurons=5\n",
    "number_of_samples=3\n",
    "weights=Variable(np.random.randn(number_of_neurons,input_dimensions))\n",
    "bias=Variable(np.random.randn(number_of_neurons,1))\n",
    "X = placeholder()\n",
    "WX = matmul(weights,X)\n",
    "net=add(WX,bias)\n",
    "a=sigmoid(net)\n",
    "\n",
    "session = Session()\n",
    "output = session.run(a, {X: np.random.randn(input_dimensions,number_of_samples)})\n",
    "print(\"weights=\",weights.value)\n",
    "print(\"bias=\",bias.value)\n",
    "print(\"X=\",X.output)\n",
    "print(\"output=\",output)\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
