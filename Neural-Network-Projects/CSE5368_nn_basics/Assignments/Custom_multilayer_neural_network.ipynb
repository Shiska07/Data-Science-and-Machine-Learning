{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raut, Shiska\n",
    "# 1001_526_329\n",
    "# 2023_02_26\n",
    "# Assignment_01_01\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# returns a weight matrix for of size r X c + 1 (including bias) \n",
    "def get_weights_matrix(r,c,seed):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    weight_matrix = np.random.randn(r, c + 1)   # c + 1 for bias\n",
    "\n",
    "    return weight_matrix\n",
    "\n",
    "# given input 'x' and weight matrix 'W' return logsig(W*x) \n",
    "def get_layer_output(x, W):\n",
    "\n",
    "    net_value = np.dot(W, x)\n",
    "    activation_value = 1.0 / (1 + np.exp(-net_value))\n",
    "    \n",
    "    return activation_value\n",
    "\n",
    "# cakculates mean squared error for a single sample\n",
    "def get_mean_squared_error(y_train_sample, y_pred_sample):\n",
    "    \n",
    "    # get the numer of rows for output value\n",
    "    n = y_train_sample.shape[0]\n",
    "    \n",
    "    # sum of squared error\n",
    "    sse = np.sum(((y_train_sample - y_pred_sample)**2), axis = 1)\n",
    "    \n",
    "    # mean squared error\n",
    "    mse = sse/n\n",
    "    \n",
    "    return mse\n",
    "\n",
    "def multi_layer_nn(X_train,Y_train,X_test,Y_test,layers,alpha,epochs,h=0.00001,seed=2):\n",
    "    \n",
    "    # get number of features and number of samples\n",
    "    n_feat_train, n_train = X_train.shape\n",
    "    __ , n_test = X_test.shape\n",
    "    \n",
    "    #get number of layers and initialize list to store weights for each layer\n",
    "    n_layers = len(layers)\n",
    "    weights_list = [] \n",
    "    \n",
    "    # get weights for each layer\n",
    "    for i in range(n_layers):\n",
    "        \n",
    "        if i == 0:\n",
    "            # get weights for first layer\n",
    "            weights_list.append(get_weights_matrix(layers[0], n_feat_train, seed))\n",
    "        else:\n",
    "            n_nodes = layers[i]\n",
    "            n_input = layers[i - 1]\n",
    "            weights_list.append(get_weights_matrix(n_nodes, n_input, seed))\n",
    "    \n",
    "    x_sample = np.ones((n_feat_train + 1, 1))\n",
    "    x_sample[1::] = X_train[:,0].reshape((n_feat_train, 1))\n",
    "    \n",
    "    print(get_layer_output(x_sample, weights_list[0]))\n",
    "        \n",
    "    # alpha: learning rate\n",
    "    # epochs: number of epochs for training.\n",
    "    # h: step size\n",
    "    # seed: random number generator seed for initializing the weights.\n",
    "    # return: This function should return a list containing 3 elements:\n",
    "        # The first element of the return list should be a list of weight matrices.\n",
    "        # Each element of the list corresponds to the weight matrix of the corresponding layer.\n",
    "\n",
    "        # The second element should be a one dimensional array of numbers\n",
    "        # representing the average mse error after each epoch. Each error should\n",
    "        # be calculated by using the X_test array while the network is frozen.\n",
    "        # This means that the weights should not be adjusted while calculating the error.\n",
    "\n",
    "        # The third element should be a two-dimensional array [output_dimensions,nof_test_samples]\n",
    "        # representing the actual output of network when X_test is used as input.\n",
    "\n",
    "    # Notes:\n",
    "    # DO NOT use any other package other than numpy\n",
    "    # Bias should be included in the weight matrix in the first column.\n",
    "    # Assume that the activation functions for all the layers are sigmoid.\n",
    "    # Use MSE to calculate error.\n",
    "    # Use gradient descent for adjusting the weights.\n",
    "    # use centered difference approximation to calculate partial derivatives.\n",
    "    # (f(x + h)-f(x - h))/2*h\n",
    "    # Reseed the random number generator when initializing weights for each layer.\n",
    "    # i.e., Initialize the weights for each layer by:\n",
    "    # np.random.seed(seed)\n",
    "    # np.random.randn()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04125537]\n",
      " [0.99982438]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    # This function calculates the sigmoid function\n",
    "    # x: input\n",
    "    # return: sigmoid(x)\n",
    "    # Your code goes here\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def create_toy_data_nonlinear(n_samples=1000):\n",
    "    X = np.zeros((n_samples, 4))\n",
    "    X[:, 0] = np.linspace(-1, 1, n_samples)\n",
    "    X[:, 1] = np.linspace(-1, 1, n_samples)\n",
    "    X[:, 2] = np.linspace(-1, 1, n_samples)\n",
    "    X[:, 3] = np.linspace(-1, 1, n_samples)\n",
    "\n",
    "    y = X[:, 0]**2 + 2*X[:, 1]  - 0.5*X[:, 2] + X[:, 3]**3 + 0.3\n",
    "\n",
    "    # shuffle X and y\n",
    "    idx = np.arange(n_samples)\n",
    "    np.random.shuffle(idx)\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def create_toy_data_nonlinear_2d(n_samples=1000):\n",
    "    X = np.zeros((n_samples, 4))\n",
    "    X[:, 0] = np.linspace(-1, 1, n_samples)\n",
    "    X[:, 1] = np.linspace(-1, 1, n_samples)\n",
    "    X[:, 2] = np.linspace(-1, 1, n_samples)\n",
    "    X[:, 3] = np.linspace(-1, 1, n_samples)\n",
    "    y = np.zeros((n_samples, 2))\n",
    "    y[:, 0] = 0.5*X[:, 0] -0.2 * X[:, 1]**2 - 0.2*X[:, 2] + X[:, 3]*X[:,1] - 0.1\n",
    "    y[:, 1] = 1.5 * X[:, 0] + 1.25 * X[:, 1]*X[:, 0] + 0.4 * X[:, 2] * X[:, 0]\n",
    "\n",
    "    # shuffle X and y\n",
    "    idx = np.arange(n_samples)\n",
    "    np.random.shuffle(idx)\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def test_can_fit_data_test():\n",
    "    np.random.seed(12345)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X, y = create_toy_data_nonlinear(n_samples=110)\n",
    "    y = sigmoid(y)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    Y_train = Y_train.reshape(-1,1)\n",
    "    Y_train = Y_train\n",
    "    Y_test = Y_test.reshape(-1,1)\n",
    "    Y_test = Y_test\n",
    "\n",
    "    multi_layer_nn(X_train,Y_train,X_test,Y_test,[2,1],alpha=0.35,epochs=1000,h=1e-8,seed=1234)\n",
    "    \n",
    "    return 0\n",
    "\n",
    "test_can_fit_data_test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09194992, -1.46335065,  1.08179168],\n",
       "       [-0.23932517, -0.49112914, -1.00227201],\n",
       "       [ 0.9188215 , -1.1036321 ,  0.62649346]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(22)\n",
    "np.random.randn(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
