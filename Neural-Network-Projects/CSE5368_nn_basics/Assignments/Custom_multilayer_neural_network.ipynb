{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raut, Shiska\n",
    "# 1001_526_329\n",
    "# 2023_02_26\n",
    "# Assignment_01_01\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def multi_layer_nn(X_train,Y_train,X_test,Y_test,layers,alpha,epochs,h=0.00001,seed=2):\n",
    "    \n",
    "    # get number of features and number of samples\n",
    "    n_feat_train, n_train = X_train.shape\n",
    "    n_feat_test, n_test = X_test.shape\n",
    "    \n",
    "    # This function creates and trains a multi-layer neural Network\n",
    "    # X_train: Array of input for training [input_dimensions,nof_train_samples]\n",
    "\n",
    "    # Y_train: Array of desired outputs for training samples [output_dimensions,nof_train_samples]\n",
    "    # X_test: Array of input for testing [input_dimensions,nof_test_samples]\n",
    "    # Y_test: Array of desired outputs for test samples [output_dimensions,nof_test_samples]\n",
    "    # layers: array of integers representing number of nodes in each layer\n",
    "    # alpha: learning rate\n",
    "    # epochs: number of epochs for training.\n",
    "    # h: step size\n",
    "    # seed: random number generator seed for initializing the weights.\n",
    "    # return: This function should return a list containing 3 elements:\n",
    "        # The first element of the return list should be a list of weight matrices.\n",
    "        # Each element of the list corresponds to the weight matrix of the corresponding layer.\n",
    "\n",
    "        # The second element should be a one dimensional array of numbers\n",
    "        # representing the average mse error after each epoch. Each error should\n",
    "        # be calculated by using the X_test array while the network is frozen.\n",
    "        # This means that the weights should not be adjusted while calculating the error.\n",
    "\n",
    "        # The third element should be a two-dimensional array [output_dimensions,nof_test_samples]\n",
    "        # representing the actual output of network when X_test is used as input.\n",
    "\n",
    "    # Notes:\n",
    "    # DO NOT use any other package other than numpy\n",
    "    # Bias should be included in the weight matrix in the first column.\n",
    "    # Assume that the activation functions for all the layers are sigmoid.\n",
    "    # Use MSE to calculate error.\n",
    "    # Use gradient descent for adjusting the weights.\n",
    "    # use centered difference approximation to calculate partial derivatives.\n",
    "    # (f(x + h)-f(x - h))/2*h\n",
    "    # Reseed the random number generator when initializing weights for each layer.\n",
    "    # i.e., Initialize the weights for each layer by:\n",
    "    # np.random.seed(seed)\n",
    "    # np.random.randn()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    # This function calculates the sigmoid function\n",
    "    # x: input\n",
    "    # return: sigmoid(x)\n",
    "    # Your code goes here\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def create_toy_data_nonlinear(n_samples=1000):\n",
    "    X = np.zeros((n_samples, 4))\n",
    "    X[:, 0] = np.linspace(-1, 1, n_samples)\n",
    "    X[:, 1] = np.linspace(-1, 1, n_samples)\n",
    "    X[:, 2] = np.linspace(-1, 1, n_samples)\n",
    "    X[:, 3] = np.linspace(-1, 1, n_samples)\n",
    "\n",
    "    y = X[:, 0]**2 + 2*X[:, 1]  - 0.5*X[:, 2] + X[:, 3]**3 + 0.3\n",
    "\n",
    "    # shuffle X and y\n",
    "    idx = np.arange(n_samples)\n",
    "    np.random.shuffle(idx)\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def create_toy_data_nonlinear_2d(n_samples=1000):\n",
    "    X = np.zeros((n_samples, 4))\n",
    "    X[:, 0] = np.linspace(-1, 1, n_samples)\n",
    "    X[:, 1] = np.linspace(-1, 1, n_samples)\n",
    "    X[:, 2] = np.linspace(-1, 1, n_samples)\n",
    "    X[:, 3] = np.linspace(-1, 1, n_samples)\n",
    "    y = np.zeros((n_samples, 2))\n",
    "    y[:, 0] = 0.5*X[:, 0] -0.2 * X[:, 1]**2 - 0.2*X[:, 2] + X[:, 3]*X[:,1] - 0.1\n",
    "    y[:, 1] = 1.5 * X[:, 0] + 1.25 * X[:, 1]*X[:, 0] + 0.4 * X[:, 2] * X[:, 0]\n",
    "\n",
    "    # shuffle X and y\n",
    "    idx = np.arange(n_samples)\n",
    "    np.random.shuffle(idx)\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def test_can_fit_data_test():\n",
    "    np.random.seed(12345)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X, y = create_toy_data_nonlinear(n_samples=110)\n",
    "    y = sigmoid(y)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    Y_train = Y_train.reshape(-1,1)\n",
    "    Y_train = Y_train\n",
    "    Y_test = Y_test.reshape(-1,1)\n",
    "    Y_test = Y_test\n",
    "\n",
    "    [W, err, Out] = multi_layer_nn(X_train,Y_train,X_test,Y_test,[2,1],alpha=0.35,epochs=1000,h=1e-8,seed=1234)\n",
    "    assert err[1] < err[0]\n",
    "    assert err[2] < err[1]\n",
    "    assert err[3] < err[2]\n",
    "    assert err[10] < 0.15\n",
    "    assert err[999] < 0.0024\n",
    "    assert abs(err[9] - 0.11626994890207282) < 1e-5\n",
    "\n",
    "\n",
    "\n",
    "def test_can_fit_data_test_2d():\n",
    "    np.random.seed(1234)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X, y = create_toy_data_nonlinear_2d(110)\n",
    "    y = sigmoid(y)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    Y_train = Y_train.reshape(-1,2)\n",
    "    Y_train = Y_train\n",
    "    Y_test = Y_test.reshape(-1,2)\n",
    "    Y_test = Y_test\n",
    "\n",
    "    [W, err, Out] = multi_layer_nn(X_train,Y_train,X_test,Y_test,[2,2],alpha=0.35,epochs=1000,h=1e-8,seed=1234)\n",
    "    assert err[1] < err[0]\n",
    "    assert err[2] < err[1]\n",
    "    assert err[3] < err[2]\n",
    "    assert err[10] < 0.5\n",
    "    assert err[999] < 0.0068\n",
    "    assert abs(err[9] - 0.11573813086247146) < 1e-5\n",
    "\n",
    "\n",
    "def test_check_weight_init():\n",
    "    np.random.seed(1234)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X, y = create_toy_data_nonlinear(n_samples=110)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.1, random_state=1234)\n",
    "    Y_train = Y_train.reshape(-1,1)\n",
    "    Y_train = Y_train\n",
    "    Y_test = Y_test.reshape(-1,1)\n",
    "    Y_test = Y_test\n",
    "\n",
    "    [W, err, Out] = multi_layer_nn(X_train,Y_train,X_test,Y_test,[2,1],alpha=0.35,epochs=0,h=1e-8,seed=1234)\n",
    "    assert np.allclose(W[0], np.array([[-0.41675785, -0.05626683],\n",
    "       [-2.1361961 ,  1.64027081],\n",
    "       [-1.79343559, -0.84174737],\n",
    "       [ 0.50288142, -1.24528809],\n",
    "       [-1.05795222, -0.90900761]]))\n",
    "    assert np.allclose(W[1], np.array([[-0.41675785],\n",
    "       [-0.05626683],\n",
    "       [-2.1361961 ]]))\n",
    "\n",
    "def test_large_h_test():\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X, y = create_toy_data_nonlinear(n_samples=110)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    Y_train = Y_train.reshape(-1,1)\n",
    "    Y_train = Y_train\n",
    "    Y_test = Y_test.reshape(-1,1)\n",
    "    Y_test = Y_test\n",
    "\n",
    "    [W, err_1, Out] = multi_layer_nn(X_train,Y_train,X_test,Y_test,[2,1],alpha=0.35,epochs=100,h=1,seed=2)\n",
    "    [W, err_2, Out] = multi_layer_nn(X_train, Y_train, X_test, Y_test, [2, 1], alpha=0.35,\n",
    "                                   epochs=100, h=1e-8, seed=2)\n",
    "    assert abs(err_1[-1] - err_1[0]) < 1e-3 or err_1[-1] > err_1[0] # with large h the error should either stay the same or may increase\n",
    "    assert abs(err_2[-1] - err_2[0]) > 0.1 # with small h the error should decrease\n",
    "\n",
    "\n",
    "def test_large_alpha_test():\n",
    "    # if alpha is too large, the weights will change too much with each update, and the error will either increase or not improve much\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X, y = create_toy_data_nonlinear(n_samples=110)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    Y_train = Y_train.reshape(-1,1)\n",
    "    Y_train = Y_train\n",
    "    Y_test = Y_test.reshape(-1,1)\n",
    "    Y_test = Y_test\n",
    "\n",
    "    [W, err, Out] = multi_layer_nn(X_train,Y_train,X_test,Y_test,[2,1],alpha=10,epochs=100,h=1,seed=2)\n",
    "    assert err[-1] > 0.4\n",
    "\n",
    "\n",
    "def test_small_alpha_test():\n",
    "    # if the alpha value is very small (e.g. 1e-9), the weights should not change much with each update, and the error should not decrease\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X, y = create_toy_data_nonlinear(n_samples=110)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    Y_train = Y_train.reshape(-1,1)\n",
    "    Y_train = Y_train\n",
    "    Y_test = Y_test.reshape(-1,1)\n",
    "    Y_test = Y_test\n",
    "\n",
    "    [W, err, Out] = multi_layer_nn(X_train,Y_train,X_test,Y_test,[2,1],alpha=1e-9,epochs=1000,h=1e-8,seed=2)\n",
    "    assert abs(err[-1] - err[-2]) < 1e-5\n",
    "    assert abs(err[1] - err[0]) < 1e-5\n",
    "\n",
    "def test_number_of_nodes_test():\n",
    "    # check if the number of nodes is being used in creating the weight matrices\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X, y = create_toy_data_nonlinear(n_samples=110)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    Y_train = Y_train.reshape(-1,1)\n",
    "    Y_train = Y_train\n",
    "    Y_test = Y_test.reshape(-1,1)\n",
    "    Y_test = Y_test\n",
    "\n",
    "    [W, err, Out] = multi_layer_nn(X_train,Y_train,X_test,Y_test,[100,1],alpha=1e-9,epochs=0,h=1e-8,seed=2)\n",
    "\n",
    "    assert W[0].shape == (5, 100)\n",
    "    assert W[1].shape == (101, 1)\n",
    "\n",
    "    [W, err, Out] = multi_layer_nn(X_train, Y_train, X_test, Y_test, [42, 1], alpha=1e-9,\n",
    "                                   epochs=0, h=1e-8, seed=2)\n",
    "    assert W[0].shape == (5, 42)\n",
    "    assert W[1].shape == (43, 1)\n",
    "\n",
    "    [W, err, Out] = multi_layer_nn(X_train, Y_train, X_test, Y_test, [42, 2], alpha=1e-9,\n",
    "                                   epochs=0, h=1e-8, seed=2)\n",
    "    assert W[0].shape == (5, 42)\n",
    "    assert W[1].shape == (43, 2)\n",
    "\n",
    "def test_check_output_shape():\n",
    "    # check if the number of nodes is being used in creating the weight matrices\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X, y = create_toy_data_nonlinear(n_samples=110)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    Y_train = Y_train.reshape(-1, 1)\n",
    "    Y_train = Y_train\n",
    "    Y_test = Y_test.reshape(-1, 1)\n",
    "    Y_test = Y_test\n",
    "\n",
    "    [W, err, Out] = multi_layer_nn(X_train, Y_train, X_test, Y_test, [100, 1], alpha=1e-9, epochs=0, h=1e-8, seed=2)\n",
    "    assert Out.shape == Y_test.shape\n",
    "\n",
    "def test_check_output_shape_2d():\n",
    "    np.random.seed(1234)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X, y = create_toy_data_nonlinear_2d(110)\n",
    "    y = sigmoid(y)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    Y_train = Y_train.reshape(-1,2)\n",
    "    Y_train = Y_train\n",
    "    Y_test = Y_test.reshape(-1,2)\n",
    "    Y_test = Y_test\n",
    "\n",
    "    [W, err, Out] = multi_layer_nn(X_train,Y_train,X_test,Y_test,[2,2],alpha=0.35,epochs=1000,h=1e-8,seed=1234)\n",
    "    assert Out.shape == Y_test.shape\n",
    "\n",
    "def test_check_output_values():\n",
    "    np.random.seed(1234)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X, y = create_toy_data_nonlinear_2d(110)\n",
    "    y = sigmoid(y)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    Y_train = Y_train.reshape(-1,2)\n",
    "    Y_train = Y_train\n",
    "    Y_test = Y_test.reshape(-1,2)\n",
    "    Y_test = Y_test\n",
    "\n",
    "    [W, err, Out] = multi_layer_nn(X_train,Y_train,X_test,Y_test,[2,2],alpha=0.35,epochs=0,h=1e-8,seed=1234)\n",
    "    expected_Out = np.array([[0.01974967, 0.71039717], [0.05156214, 0.64169265], [0.15171837, 0.49588593], [0.17392495, 0.47804094],\n",
    "                             [0.05403315, 0.63605476], [0.26409141, 0.44140354], [0.24360667, 0.44452713], [0.02096201, 0.71095784],\n",
    "                             [0.29556927, 0.44331848], [0.05667479, 0.63019167], [0.01997007, 0.71058803]])\n",
    "    assert np.allclose(Out, expected_Out, atol=1e-5)\n",
    "\n",
    "def test_check_weight_update():\n",
    "    np.random.seed(1234)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X, y = create_toy_data_nonlinear_2d(110)\n",
    "    y = sigmoid(y)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    Y_train = Y_train.reshape(-1,2)\n",
    "    Y_train = Y_train\n",
    "    Y_test = Y_test.reshape(-1,2)\n",
    "    Y_test = Y_test\n",
    "    np.random.seed(1234)\n",
    "    [W_before, err, Out] = multi_layer_nn(X_train,Y_train,X_test,Y_test,[2,2],alpha=0.2,epochs=0,h=1e-8,seed=1234)\n",
    "    np.random.seed(1234)\n",
    "    [W_after, err, Out] = multi_layer_nn(X_train, Y_train, X_test, Y_test, [2, 2], alpha=0.2, epochs=1, h=1e-8, seed=1234)\n",
    "    delta1 = (W_after[0] - W_before[0])\n",
    "    delta2 = (W_after[1] - W_before[1])\n",
    "    correct_delta1 = np.array([[-0.00188851, -0.00329594],[ 0.00045242, -0.0021995 ],[ 0.00045242, -0.0021995 ], [ 0.00045242, -0.0021995 ], [ 0.00045242, -0.0021995 ]])\n",
    "    correct_delta2 = np.array([[ 0.00783472,  0.00257216], [ 0.00174925, -0.00355675], [ 0.00291452, -0.00106518]])\n",
    "    assert np.allclose(delta1, correct_delta1, atol=1e-5)\n",
    "    assert np.allclose(delta2, correct_delta2, atol=1e-5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
