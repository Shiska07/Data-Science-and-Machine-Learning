{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create feature matrix and and label vectors\n",
    "The function 'get_vectors' takes a filename as input and returns a matrix X containing feature vectors and vector y containing target labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(filename):\n",
    "    try:\n",
    "        f = open(filename, 'r')\n",
    "    except OSError:\n",
    "        print(f'{filename} could not be opened.\\n')\n",
    "        sys.exit()\n",
    "        \n",
    "    # initialize list to store feature and labels for training data\n",
    "    features = []             \n",
    "    labels = []\n",
    "    \n",
    "    with f:\n",
    "        line = f.readline()\n",
    "        while line != '':\n",
    "            # strip newline and outer parenthesis\n",
    "            line = line.strip('\\n')\n",
    "            line = line.strip('( )')\n",
    "            \n",
    "            # extrace label and append to labels list\n",
    "            single_label = line.split('), ')[-1]\n",
    "            labels.append(single_label)\n",
    "            \n",
    "            # extrace features and append to features list\n",
    "            feat = line.split('), ')[0].split(', ')\n",
    "            features.append(feat)\n",
    "            \n",
    "            # read next line\n",
    "            line = f.readline()\n",
    "        \n",
    "        # create dataframe of features and append labels\n",
    "        X = np.array(features, dtype = float, ndmin = 2)\n",
    "        \n",
    "        # convert labels list to array\n",
    "        y = np.array(labels, dtype = str, ndmin = 2)\n",
    "        \n",
    "        return X, y.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates euclidean distance between training datapoints and test data point\n",
    "def get_euclidean_distance(X_train, p):\n",
    "    \n",
    "    # n = total number of datapoints, f_n = total number of features\n",
    "    n, f_n = X_train.shape\n",
    "    \n",
    "    sum_of_squared_diff = np.zeros((n, 1), dtype = float)\n",
    "    \n",
    "    # use vectorization to get sum of squared difference\n",
    "    for i in range(f_n):\n",
    "        x_vector = X_train[:,i].reshape((n,1))\n",
    "        sum_of_squared_diff = sum_of_squared_diff + (x_vector - p[i])**2\n",
    "        \n",
    "    # take sq root to get array of cartesianeuclidean distance\n",
    "    euc_dist = np.sqrt(sum_of_squared_diff)\n",
    "    \n",
    "    return euc_dist\n",
    "\n",
    "# calculates manhattan distance between training datapoints and test data point\n",
    "def get_manhattan_distance(X_train, p):\n",
    "    \n",
    "    # n = total number of datapoints, f_n = total number of features\n",
    "    n, f_n = X_train.shape\n",
    "    \n",
    "    sum_of_abs_diff = np.zeros((n, 1), dtype = float)\n",
    "    \n",
    "    # use vectorization to get sum of squared difference\n",
    "    for i in range(f_n):\n",
    "        x_vector = X_train[:,i].reshape((n,1))\n",
    "        sum_of_abs_diff = sum_of_abs_diff + abs(x_vector - p[i])\n",
    "        \n",
    "    # take sq root to get array of cartesianeuclidean distance\n",
    "    man_dist = np.sqrt(sum_of_abs_diff)\n",
    "    \n",
    "    return man_dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Implementation \n",
    "\n",
    "This function takes training data, prediction datapoint and number of neighbors as the argument and returns\n",
    "a prediction class based on highest MAP value i.e. argmax_c P(class|<data>)\n",
    "\n",
    "Key notes:\n",
    "1. Cartesian/euclidean distance is used as a default distance measure.\n",
    "2. The distance and labels of the first 'k' neighbors are printed.\n",
    "3. MAP values of each class is calculated and stored in a dictionary with class labels as the key.\n",
    "4. Tie breaker: If two or more classes have the same highest probability value, the first occuring class is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_class_with_knn(X_train, y_train, p, k, dist_type):\n",
    "    \n",
    "    # n = total number of datapoints, f_n = total number of features\n",
    "    n, f_n = X_train.shape\n",
    "    \n",
    "    if dist_type == 'euclidean':\n",
    "        # get euclidean distance array\n",
    "        dist_arr = get_euclidean_distance(X_train, p)\n",
    "    elif dist_type == 'manhattan':\n",
    "        # get euclidean distance array\n",
    "        dist_arr = get_manhattan_distance(X_train, p)\n",
    "    \n",
    "    # concat with y_train labels and sort in ascending order of the distance\n",
    "    dist_arr = np.concatenate((dist_arr, y_train), axis = 1)\n",
    "    \n",
    "    # sort wrt the euclidean distance(first col)\n",
    "    dist_arr = dist_arr[dist_arr[:,0].argsort()]\n",
    "    \n",
    "    # save k nearest neighbors\n",
    "    knn = dist_arr[0:k,:]\n",
    "    \n",
    "    # save labels of the k nearest neighbors as a list\n",
    "    knn_labels = list(dist_arr[0:k,1]) \n",
    "    \n",
    "    # calculate class probability\n",
    "    class_probability = {}\n",
    "    class_probability['Metal'] = knn_labels.count('Metal')/n\n",
    "    class_probability['Ceramic'] = knn_labels.count('Ceramic')/n\n",
    "    class_probability['Plastic'] = knn_labels.count('Plastic')/n\n",
    "    \n",
    "    max_probability = 0\n",
    "    max_probability_class = max(class_probability, key = class_probability.get)\n",
    "    \n",
    "    for i in class_probability:\n",
    "        \n",
    "    # return the class with maximum probability and the probablity value\n",
    "    return max(class_probability, key = class_probability.get), class_probability[max(class_probability, key = class_probability.get)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide training filename & prediction data point\n",
    "The file must contain 1 datapoint per line in format (( height, diameter, weight, hue ), label ) which is similar to the format provided for the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide filename\n",
    "filename = str(input('Enter file containing training data: '))\n",
    "\n",
    "# provide prediction datapoint\n",
    "h_p = float(input('Enter height: '))\n",
    "d_p = float(input('Enter diameter: '))\n",
    "w_p = float(input('Enter weight: '))\n",
    "c_p = float(input('Enter hue/color: '))\n",
    "\n",
    "# provide 'k' value\n",
    "k = int(input('Enter value of k: '))\n",
    "\n",
    "# save prediction datapont as a 1-D numpy array\n",
    "p = np.array([h_p, d_p, w_p, c_p])\n",
    "\n",
    "# get training data as vectors\n",
    "X, y = get_vectors(filename)\n",
    "\n",
    "# get prediction\n",
    "preidicted_class, prob_value = predict_class_with_knn(X, y, p, k)\n",
    "print(f\"\\nThe datapoint belongs to class '{preidicted_class}' with a probability of {prob_value:.4f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-one-out evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes the entire feature dataset(X) , correct data point labels(y), the number of neighbors to consider(k) and the type of distance to use for nearest neighbor calculation(dist_type) as arguments and returns the accuracy (total correct predictions/ total datapoints). \n",
    "\n",
    "The datapoint ot be left out and tested is chosen according to its index (i.e. item at index 0 is left out during the first iteration and item at index n-1 is left our during the last iteration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out_validation(X, y, k, dist_type):\n",
    "    \n",
    "    # get number of training items and number of features\n",
    "    n, f_n = X.shape\n",
    "    \n",
    "    # prediction labels generated by 'predict_class_with_knn' will be stored in this list\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        X_train = np.delete(X, i, axis = 0)\n",
    "        y_train = np.delete(y, i, axis = 0)\n",
    "        X_test = X[i,:]\n",
    "        pred, prob = predict_class_with_knn(X_train, y_train, X_test, k, dist_type)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    # convert prediction list to numpy array\n",
    "    predictions = np.array(predictions, dtype = str, ndmin = 2)\n",
    "    predictions = predictions.reshape(predictions.shape[1], 1)\n",
    "    \n",
    "    # return accuracy\n",
    "    return (np.sum(y == predictions))/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter filename for leave-one-out-evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter file for leave-one-out-evaluation data: Data\\\\2_c_d_e.txt\n"
     ]
    }
   ],
   "source": [
    "filename = str(input('Enter file for leave-one-out-evaluation data: '))\n",
    "\n",
    "X, y = get_vectors(filename)\n",
    "\n",
    "# initialize distionary to store accuracy values for different 'k' values\n",
    "accuracy_euc = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K = 1, 3 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy for various values of 'k'\n",
    "accuracy_euc[1] = leave_one_out_validation(X, y, 1, dist_type = 'euclidean')\n",
    "accuracy_euc[3] = leave_one_out_validation(X, y, 3, dist_type = 'euclidean')\n",
    "accuracy_euc[5] = leave_one_out_validation(X, y, 5, dist_type = 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(1, 0.425), (3, 0.38333333333333336), (5, 0.4083333333333333)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_euc.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
