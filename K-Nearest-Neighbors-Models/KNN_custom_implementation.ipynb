{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from file and create vectors\n",
    "The function 'get_vectors' takes a filename as input and returns a matrix X containing each row was a datapoint and vector y containing target labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(filename):\n",
    "    try:\n",
    "        f = open(filename, 'r')\n",
    "    except OSError:\n",
    "        print(f'{filename} could not be opened.\\n')\n",
    "        sys.exit()\n",
    "        \n",
    "    # initialize list to store feature and labels for training data\n",
    "    features = []             \n",
    "    labels = []\n",
    "    \n",
    "    with f:\n",
    "        line = f.readline()\n",
    "        while line != '':\n",
    "            # strip newline and outer parenthesis\n",
    "            line = line.strip('\\n')\n",
    "            line = line.strip('( )')\n",
    "            \n",
    "            # extrace label and append to labels list\n",
    "            single_label = line.split('), ')[-1]\n",
    "            labels.append(single_label)\n",
    "            \n",
    "            # extrace features and append to features list\n",
    "            feat = line.split('), ')[0].split(', ')\n",
    "            features.append(feat)\n",
    "            \n",
    "            # read next line\n",
    "            line = f.readline()\n",
    "        \n",
    "        # create dataframe of features and append labels\n",
    "        X = np.array(features, dtype = float, ndmin = 2)\n",
    "        \n",
    "        # convert labels list to array\n",
    "        y = np.array(labels, dtype = str, ndmin = 2)\n",
    "        \n",
    "        return X, y.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates euclidean distance between training datapoints and test data point\n",
    "def get_euclidean_distance(X_train, p):\n",
    "    \n",
    "    # n = total number of datapoints, f_n = total number of features\n",
    "    n, f_n = X_train.shape\n",
    "    \n",
    "    sum_of_squared_diff = np.zeros((n, 1), dtype = float)\n",
    "    \n",
    "    # use vectorization to get sum of squared difference\n",
    "    for i in range(f_n):\n",
    "        x_vector = X_train[:,i].reshape((n,1))\n",
    "        sum_of_squared_diff = sum_of_squared_diff + (x_vector - p[i])**2\n",
    "        \n",
    "    # take sq root to get array of cartesianeuclidean distance\n",
    "    euc_dist = np.sqrt(sum_of_squared_diff)\n",
    "    \n",
    "    return euc_dist\n",
    "\n",
    "# This function calculates manhattan distance between training datapoints and test data point\n",
    "def get_manhattan_distance(X_train, p):\n",
    "    \n",
    "    # n = total number of datapoints, f_n = total number of features\n",
    "    n, f_n = X_train.shape\n",
    "    \n",
    "    sum_of_abs_diff = np.zeros((n, 1), dtype = float)\n",
    "    \n",
    "    # use vectorization to get sum of squared difference\n",
    "    for i in range(f_n):\n",
    "        x_vector = X_train[:,i].reshape((n,1))\n",
    "        sum_of_abs_diff = sum_of_abs_diff + abs(x_vector - p[i])\n",
    "        \n",
    "    # take sq root to get array of cartesianeuclidean distance\n",
    "    man_dist = np.sqrt(sum_of_abs_diff)\n",
    "    \n",
    "    return man_dist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-one-out evaluation function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes the entire feature dataset(X) , correct data point labels(y), the number of neighbors to consider(k) and the type of distance to use for nearest neighbor calculation(dist_type) as arguments and returns the accuracy (total correct predictions/ total datapoints). \n",
    "\n",
    "The datapoint ot be left out and tested is chosen according to its index (i.e. item at index 0 is left out during the first iteration and item at index n-1 is left our during the last iteration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out_evaluation(X, y, k, dist_type):\n",
    "    \n",
    "    # get number of training items and number of features\n",
    "    n, f_n = X.shape\n",
    "    \n",
    "    # prediction labels generated by 'predict_class_with_knn' will be stored in this list\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        X_train = np.delete(X, i, axis = 0)\n",
    "        y_train = np.delete(y, i, axis = 0)\n",
    "        X_test = X[i,:]\n",
    "        pred, prob = predict_class_with_knn(X_train, y_train, X_test, k, dist_type)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    # convert prediction list to numpy array\n",
    "    predictions = np.array(predictions, dtype = str, ndmin = 2)\n",
    "    predictions = predictions.reshape(predictions.shape[1], 1)\n",
    "    \n",
    "    # return accuracy\n",
    "    return (np.sum(y == predictions))/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Implementation \n",
    "\n",
    "This function takes training data, prediction datapoint and number of neighbors as the argument and returns\n",
    "a prediction class based on highest MAP value i.e. argmax_c P(class|<data>)\n",
    "\n",
    "Key notes:\n",
    "1. Cartesian/euclidean distance is used as a default distance measure.\n",
    "2. The distance and labels of the first 'k' neighbors are printed.\n",
    "3. MAP values of each class is calculated and stored in a dictionary with class labels as the key.\n",
    "4. Tie breaker: If two or more classes have the same highest probability value, the first occuring class is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_class_with_knn(X_train, y_train, p, k, dist_type):\n",
    "    \n",
    "    # n = total number of datapoints, f_n = total number of features\n",
    "    n, f_n = X_train.shape\n",
    "    \n",
    "    if dist_type == 'euclidean':\n",
    "        dist_arr = get_euclidean_distance(X_train, p)\n",
    "    elif dist_type == 'manhattan':\n",
    "        dist_arr = get_manhattan_distance(X_train, p)\n",
    "    \n",
    "    # concat with y_train labels and sort in ascending order of the distance\n",
    "    dist_arr = np.concatenate((dist_arr, y_train), axis = 1)\n",
    "    dist_arr = dist_arr[dist_arr[:,0].argsort()]\n",
    "    \n",
    "    # the first 'k' rows contain distance and labels of the k nearest neighbors\n",
    "    knn = dist_arr[0:k,:]\n",
    "    \n",
    "    # save labels of the k nearest neighbors as a list s.t. to count occurence\n",
    "    knn_labels = list(knn[:,1])\n",
    "    \n",
    "    # class labels\n",
    "    class_labels = list(set(knn_labels))\n",
    "    \n",
    "    # calculate class probability\n",
    "    class_probability = {}\n",
    "    class_probability['Metal'] = knn_labels.count('Metal')/n\n",
    "    class_probability['Ceramic'] = knn_labels.count('Ceramic')/n\n",
    "    class_probability['Plastic'] = knn_labels.count('Plastic')/n\n",
    "    \n",
    "    '''\n",
    "    The knn_label_prob list will store class probability values for each of the k nearest neighbors w.r.t their class \n",
    "    label so that if a tie occurs between two classes, class label of the neighbor that is closest to the test datapoint\n",
    "    will be chosen.\n",
    "    '''\n",
    "\n",
    "    knn_label_prob = []\n",
    "    for idx, item in enumerate(knn_labels):\n",
    "        knn_label_prob.append(class_probability[item])\n",
    "    \n",
    "    \n",
    "    max_class_prob_idx = 0\n",
    "    max_class_prob = float(0)\n",
    "    \n",
    "    for i in range(k):\n",
    "        if knn_label_prob[i] > max_class_prob:\n",
    "            max_class_prob = knn_label_prob[i]\n",
    "            max_class_prob_idx = i\n",
    "    \n",
    "    # return the class with maximum MLP and the probablity value\n",
    "    return knn_labels[max_class_prob_idx], knn_label_prob[max_class_prob_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide training filename & prediction data point\n",
    "The file must contain 1 datapoint per line in format (( height, diameter, weight, hue ), label ) which is similar to the format provided for the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter file containing training data: Data\\\\2_a_train.txt\n",
      "Enter file containing test data: Data\\\\2_a_test.txt\n",
      "Enter value of k: 5\n",
      "\n",
      "\n",
      "Datapoint 1 : 'Plastic' with a probability of 0.2500.\n",
      "Datapoint 2 : 'Ceramic' with a probability of 0.1667.\n",
      "Datapoint 3 : 'Plastic' with a probability of 0.2500.\n",
      "Datapoint 4 : 'Plastic' with a probability of 0.2500.\n"
     ]
    }
   ],
   "source": [
    "# provide training and test filename\n",
    "fname_train = str(input('Enter file containing training data: '))\n",
    "fname_test = str(input('Enter file containing test data: '))\n",
    "\n",
    "# provide 'k' value\n",
    "k = int(input('Enter value of k: '))\n",
    "print('\\n')\n",
    "\n",
    "# get training data as vectors\n",
    "X, y = get_vectors(fname_train)\n",
    "\n",
    "# read test file to make predictions\n",
    "with open(fname_test, 'r') as f:\n",
    "    line = f.readline()\n",
    "    i = 1\n",
    "    while line != '':\n",
    "        line = line.strip('\\n')\n",
    "        line = line.strip('( )')\n",
    "        values = line.split(', ')\n",
    "        p = np.array(values, dtype = float)\n",
    "        preidicted_class, prob_value = predict_class_with_knn(X, y, p, k, 'euclidean')\n",
    "        print(f\"Datapoint {i} : '{preidicted_class}' with a probability of {prob_value:.4f}.\")\n",
    "        i = i + 1\n",
    "        line = f.readline()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter filename for leave-one-out evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter filename for leave-one-out evaluation data: Data\\\\2_c_d_e.txt\n"
     ]
    }
   ],
   "source": [
    "fname_loo = str(input('Enter filename for leave-one-out evaluation data: '))\n",
    "\n",
    "X, y = get_vectors(fname_loo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K = 1, 3 and 5 using cartesian distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With cartesian distance:\n",
      "For k = 1 the accuracy is 0.425000.\n",
      "For k = 3 the accuracy is 0.408333.\n",
      "For k = 5 the accuracy is 0.400000.\n"
     ]
    }
   ],
   "source": [
    "# initialize distionary to store accuracy values for different 'k' values\n",
    "accuracy_euc = {}\n",
    "\n",
    "# calculate accuracy for various values of 'k'\n",
    "accuracy_euc[1] = leave_one_out_evaluation(X, y, 1, dist_type = 'euclidean')\n",
    "accuracy_euc[3] = leave_one_out_evaluation(X, y, 3, dist_type = 'euclidean')\n",
    "accuracy_euc[5] = leave_one_out_evaluation(X, y, 5, dist_type = 'euclidean')\n",
    "\n",
    "print('With cartesian distance:')\n",
    "for key, value in accuracy_euc.items():\n",
    "    print(f'For k = {key} the accuracy is {value:0.6f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: k = 1 was found to give the best performance in terms of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 d) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K = 1, 3 and 5 using manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With manhattan distance:\n",
      "For k = 1 the accuracy is 0.500000.\n",
      "For k = 3 the accuracy is 0.458333.\n",
      "For k = 5 the accuracy is 0.516667.\n"
     ]
    }
   ],
   "source": [
    "# initialize distionary to store accuracy values for different 'k' values\n",
    "accuracy_man = {}\n",
    "\n",
    "# calculate accuracy for various values of 'k'\n",
    "accuracy_man[1] = leave_one_out_evaluation(X, y, 1, dist_type = 'manhattan')\n",
    "accuracy_man[3] = leave_one_out_evaluation(X, y, 3, dist_type = 'manhattan')\n",
    "accuracy_man[5] = leave_one_out_evaluation(X, y, 5, dist_type = 'manhattan')\n",
    "\n",
    "print('With manhattan distance:')\n",
    "for key, value in accuracy_man.items():\n",
    "    print(f'For k = {key} the accuracy is {value:0.6f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: Manhattan distance is found to perform better than cartesian distance. Accuracy is highest for a value of k = 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 e) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction after removing 4th attribute (hue) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 4th attribute from X\n",
    "X = np.delete(X, 3, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 3)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape of x\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With cartesian distance after removing 4th attribute:\n",
      "For k = 1 the accuracy is 0.816667.\n",
      "For k = 3 the accuracy is 0.833333.\n",
      "For k = 5 the accuracy is 0.808333.\n"
     ]
    }
   ],
   "source": [
    "# initialize distionary to store accuracy values for different 'k' values\n",
    "accuracy_euc3= {}\n",
    "\n",
    "# calculate accuracy for various values of 'k'\n",
    "accuracy_euc3[1] = leave_one_out_evaluation(X, y, 1, dist_type = 'euclidean')\n",
    "accuracy_euc3[3] = leave_one_out_evaluation(X, y, 3, dist_type = 'euclidean')\n",
    "accuracy_euc3[5] = leave_one_out_evaluation(X, y, 5, dist_type = 'euclidean')\n",
    "\n",
    "print('With cartesian distance after removing 4th attribute:')\n",
    "for key, value in accuracy_euc3.items():\n",
    "    print(f'For k = {key} the accuracy is {value:0.6f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: Removing the 4th attribute was found to significantly improve accuracy with highest accuracy value for k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
